{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushkrn7781/Ayushkrn/blob/main/ML_3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6toho7uRO7v"
      },
      "source": [
        "# Question 1\n",
        "## Developing an Artificial Neural Network from Scratch.\n",
        "\n",
        "In this notebook, we will be developing a feedforward neural network.\n",
        "\n",
        "We will import the MNIST dataset from keras datsets. The MNIST dataset contains images of 28x28 pixels each having values ranging from 0-255.\n",
        "It has 60000 images in the training set and 10000 images in the test set. However, we will only use the first 10000 images for training and first 1000 images for testing because our code isn't optimized and it takes time to run. We are not looking for accuracy of our network right now, we will be doing that in the next week when we will be implementing the same using Tensorflow.\n",
        "\n",
        "\n",
        "Run the first 3 cells. Your code begins after that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI17X78rktdA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrINntzulT4M",
        "outputId": "b69b0567-d538-4f16-80fe-d2b6a3352f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As discussed in the class, the images are flattened to a column.\n",
        "\n",
        "Then we are normalizing them by dividing by 255."
      ],
      "metadata": {
        "id": "dr4rLzb9ZBQE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jy7CLWCEwfn"
      },
      "outputs": [],
      "source": [
        "train_X=train_X.reshape(60000,784,1)    # flattening\n",
        "test_X=test_X.reshape(10000,784,1)\n",
        "\n",
        "train_y=train_y.reshape(60000,1)\n",
        "test_y=test_y.reshape(10000,1)\n",
        "\n",
        "train_X= train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "train_X=train_X[:10000]         #taking the first 10000 images.\n",
        "train_y=train_y[:10000]\n",
        "test_X=test_X[:1000]\n",
        "test_y=test_y[:1000]\n",
        "train_data=list(zip(train_X,train_y))\n",
        "test_data=list(zip(test_X,test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Write the code for Sigmoid Function."
      ],
      "metadata": {
        "id": "wWwDzh6kZOy3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q5a8tGYku-7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 The Network\n",
        "\n",
        "We will making a class called Network which has certain functions inside it. The cost function used is Cross-Entropy Loss. You need to code only the first 3. Rest are done for you.  There are various places within the code marked as stop_zone. Read the instructions below the code at those places to check whether your code till there is correct or not."
      ],
      "metadata": {
        "id": "cIJI5SoxbJaq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwsydmyTEt0z"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    def __init__(self,sizes): # sizes is a list containing the network.\n",
        "                              # eg : [784,128,10] means input =784 neurons,\n",
        "                              #    1st hidden layer 128 neurons, output 10 neurons.\n",
        "        self.sizes=sizes\n",
        "        self.num_layers=len(sizes)\n",
        "        self.weights= [np.random.randn(x,y) for x,y in zip(sizes[1:],sizes[:-1])]\n",
        "        self.biases= [np.random.randn(x,1) for x in sizes[1:]]\n",
        "\n",
        "# stop_zone 1. Comment out all the code below. Select all rows below. Click Ctrl + /.\n",
        "# Include the show function given below above this comment area inside the class.\n",
        "# Run this cell and then run the code with stop_zone 1 written below.\n",
        "# After this testing, don't forget tto remove the comments. Same, select all, Ctrl+/.\n",
        "\n",
        "\n",
        "    def show(self):\n",
        "      print(self.num_layers)\n",
        "      for bias in self.biases:\n",
        "          print(bias.shape)\n",
        "      for weight in self.weights:\n",
        "          print(weight.shape)\n",
        "\n",
        "    def forwardpropagation(self,a):\n",
        "        for b,w in zip(self.biases, self.weights):\n",
        "            a=sigmoid(np.dot(w,a)+b)\n",
        "            #print(a.shape)\n",
        "        return a\n",
        "\n",
        "# stop_zone 2. Comment out all the code below. Don't comment out the __init__ method else you will get error.\n",
        "# Remove comment from print(a.shape) line above. Run this cell. And run the code with stop_zone 2 written below.\n",
        "\n",
        "\n",
        "    def backpropagation(self,x,y):\n",
        "\n",
        "        # nothing to do in this 3 lines.\n",
        "        y_t = np.zeros((len(y), 10))\n",
        "        y_t[np.arange(len(y)), y] = 1\n",
        "        y_t= y_t.T\n",
        "\n",
        "        #nabla_b=dC/db and nabla_w=dC/dw. They are lists of shapes equal to that of bias and weights.\n",
        "        nabla_b=[np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w=[np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        # initially, a0 = input.\n",
        "        activation=x\n",
        "        activation_list=[x]\n",
        "\n",
        "        # step 1 : calculation of delta in last layer\n",
        "\n",
        "        # write the same forward propagation code here but while doing so store the a's.\n",
        "        for w,b in zip(self.weights,self.biases):\n",
        "            activation= sigmoid(np.dot(w,activation_list[-1])+b)\n",
        "            activation_list.append(activation)\n",
        "\n",
        "        delta= (activation_list[-1]-y)*activation_list[-1]*(1-activation_list[-1])\n",
        "        # step 2 : nabla_b and nabla_w relation with delta of last layer\n",
        "\n",
        "        nabla_b[-1]=delta\n",
        "        nabla_w[-1]=np.dot(delta,activation_list[-2].T)\n",
        "        # print(\"{} {}\".format(nabla_b[-1].shape,nabla_w[-1].shape) )\n",
        "#stop_zone 3 : remove comment from the print statement just above and run the cell for stop_zone3.\n",
        "# don't forget commenting out.\n",
        "\n",
        "        # step 3 : calculation of delta for hidden layers\n",
        "\n",
        "        for j in range(2,self.num_layers):\n",
        "            sig_der = activation_list[-j]*(1-activation_list[-j])\n",
        "            delta= (activation_list[-j]-y)*activation_list[-j]*(1-activation_list[-j])\n",
        "\n",
        "            # step 4 : nabla_b and nabla_w relation with delta of others layers\n",
        "            nabla_b[-j]= delta\n",
        "            nabla_w[-j]= np.dot(delta,activation_list[-j-1].T)\n",
        "\n",
        "#stop_zone 4 : Run the cell for stop_zone 4.\n",
        "        return (nabla_b,nabla_w)\n",
        "\n",
        "    # the functions below are complete. If you are fine till stop_zone 4, you can run\n",
        "    # this whole cell and train, test the data by running the last cell of the question.\n",
        "    # You may need to wait for around 10 minutes to see the test predictions.\n",
        "    def update_mini_batch(self,mini_batch,lr):\n",
        "        nabla_b=[np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w=[np.zeros(w.shape) for w in self.weights]\n",
        "        for x,y in mini_batch:\n",
        "            delta_b,delta_w= self.backpropagation(x,y)\n",
        "            nabla_b=[nb+ db for nb,db in zip (nabla_b,delta_b)]\n",
        "            nabla_w=[nw+dw for nw,dw in zip(nabla_w,delta_w)]\n",
        "\n",
        "        self.weights=[w- lr*nw/len(mini_batch) for w,nw in zip(self.weights,nabla_w)]\n",
        "        self.biases=[b-lr*nb/len(mini_batch) for b,nb in zip(self.biases,nabla_b)]\n",
        "\n",
        "\n",
        "    def SGD(self, train_data,epochs,mini_batch_size, lr):\n",
        "        n_train= len(train_data)\n",
        "        for i in range(epochs):\n",
        "            random.shuffle(train_data)\n",
        "            mini_batches = [train_data[k:k+ mini_batch_size] for k in range(0,n_train,mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch,lr)\n",
        "\n",
        "            self.predict(train_data)\n",
        "            print(\"Epoch {0} completed.\".format(i+1))\n",
        "\n",
        "    def predict(self,test_data):\n",
        "        test_results = [(np.argmax(self.forwardpropagation(x)),y) for x,y in test_data]\n",
        "        # returns the index of that output neuron which has highest activation\n",
        "\n",
        "        num= sum(int (x==y) for x,y in test_results)\n",
        "        print (\"{0}/{1} classified correctly.\".format(num,len(test_data)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u8cVnGamVgP",
        "outputId": "203e6a3e-07d0-4b1f-e2f4-cac8890514e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ],
      "source": [
        "# stop_zone 1\n",
        "\n",
        "# def show(self):\n",
        "#   print(self.num_layers)\n",
        "#   for bias in self.biases:\n",
        "#       print(bias.shape)\n",
        "#   for weight in self.weights:\n",
        "#       print(weight.shape)\n",
        "\n",
        "# Copy this show function from here. Paste it inside that Network Class.\n",
        "# Comment out the show function here. Run this cell.\n",
        "\n",
        "net=Network([784,128,64,10])\n",
        "net.show()\n",
        "\n",
        "# The desired output is :\n",
        "# 4\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation.\n",
        "\n",
        "# Keeping the show function over there in the Network class doesn't make any\n",
        "# difference. You may delete it if you wish. Better toss a coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7EJBF7XsSft",
        "outputId": "d6d21654-2026-4522-aacd-317d574435f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.57107516e-04],\n",
              "       [9.60215300e-01],\n",
              "       [3.54773481e-01],\n",
              "       [2.55927250e-02],\n",
              "       [9.66386826e-01],\n",
              "       [4.89579341e-01],\n",
              "       [5.06575076e-04],\n",
              "       [6.41280439e-01],\n",
              "       [8.60902179e-02],\n",
              "       [1.84312646e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# stop_zone 2\n",
        "# to use this, make sure your data is loaded. Run this cell.\n",
        "net=Network([784,128,64,10])\n",
        "#print(train_X[0])\n",
        "net.forwardpropagation(train_X[0])\n",
        "\n",
        "# The desired output is :\n",
        "# (784, 1)\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stop_zone 3\n",
        "net=Network([784,128,64,10])\n",
        "net.backpropagation(train_X[0],train_y[0])\n",
        "\n",
        "# Desired output : (10,1) (10,64)"
      ],
      "metadata": {
        "id": "FwHWyaKNhIIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bb71db-455d-40ee-a9d8-61f45557a680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[-2.48403268e-05],\n",
              "         [-6.62083644e-05],\n",
              "         [-2.90794340e-02],\n",
              "         [-2.44159966e-06],\n",
              "         [-2.98645906e-03],\n",
              "         [-3.14645127e-06],\n",
              "         [-8.30388882e-02],\n",
              "         [-1.04997153e-01],\n",
              "         [-1.47345087e-08],\n",
              "         [-6.71075999e-05],\n",
              "         [-2.57272663e-01],\n",
              "         [-5.80531669e-01],\n",
              "         [-1.24278719e-06],\n",
              "         [-3.58778936e-01],\n",
              "         [-4.44679201e-06],\n",
              "         [-7.39600395e-01],\n",
              "         [-5.44589831e-07],\n",
              "         [-9.21029343e-05],\n",
              "         [-1.06561995e-01],\n",
              "         [-2.68770988e-01],\n",
              "         [-1.05560266e+00],\n",
              "         [-9.15273545e-01],\n",
              "         [-1.67810880e-03],\n",
              "         [-1.05818705e+00],\n",
              "         [-6.28026064e-01],\n",
              "         [-2.10105917e-05],\n",
              "         [-1.80655491e-11],\n",
              "         [-9.65715015e-01],\n",
              "         [-9.88139449e-04],\n",
              "         [-6.36041837e-04],\n",
              "         [-1.07596164e-01],\n",
              "         [-7.93791313e-01],\n",
              "         [-3.27971468e-05],\n",
              "         [-2.99705905e-03],\n",
              "         [-2.26645054e-04],\n",
              "         [-1.95235893e-03],\n",
              "         [-3.05345934e-03],\n",
              "         [-1.93261871e-01],\n",
              "         [-6.82978505e-05],\n",
              "         [-4.97684215e-04],\n",
              "         [-7.47364703e-03],\n",
              "         [-2.03630598e-01],\n",
              "         [-5.43173297e-03],\n",
              "         [-6.96389596e-01],\n",
              "         [-8.15499251e-05],\n",
              "         [-2.92765334e-02],\n",
              "         [-1.87957729e-01],\n",
              "         [-1.29090413e-03],\n",
              "         [-4.56688570e-03],\n",
              "         [-6.48281476e-06],\n",
              "         [-1.10010147e-07],\n",
              "         [-1.07662486e+00],\n",
              "         [-6.67911090e-05],\n",
              "         [-9.70238141e-01],\n",
              "         [-7.10886633e-05],\n",
              "         [-4.73646381e-03],\n",
              "         [-1.57344917e-04],\n",
              "         [-2.83358893e-06],\n",
              "         [-1.74705258e-05],\n",
              "         [-1.01678684e-06],\n",
              "         [-1.70429722e-02],\n",
              "         [-2.98286874e-01],\n",
              "         [-1.03080339e+00],\n",
              "         [-7.59308690e-04],\n",
              "         [-9.47736612e-01],\n",
              "         [-2.51271221e-05],\n",
              "         [-5.91391780e-05],\n",
              "         [-1.10570898e+00],\n",
              "         [-6.44798520e-02],\n",
              "         [-7.60553843e-06],\n",
              "         [-7.39975422e-07],\n",
              "         [-2.93280440e-01],\n",
              "         [-5.80941749e-04],\n",
              "         [-3.62459001e-02],\n",
              "         [-1.33584375e-05],\n",
              "         [-4.33277531e-07],\n",
              "         [-6.17208690e-08],\n",
              "         [-1.04375187e+00],\n",
              "         [-1.23720551e-03],\n",
              "         [-1.12843951e+00],\n",
              "         [-1.24821895e-08],\n",
              "         [-7.43785962e-01],\n",
              "         [-5.37521067e-01],\n",
              "         [-1.98813514e-02],\n",
              "         [-6.82703965e-01],\n",
              "         [-2.42210674e-04],\n",
              "         [-1.24396389e-05],\n",
              "         [-2.22689052e-01],\n",
              "         [-2.60300493e-01],\n",
              "         [-4.15385972e-01],\n",
              "         [-1.11219692e+00],\n",
              "         [-1.11849201e+00],\n",
              "         [-3.90986750e-05],\n",
              "         [-3.42272605e-09],\n",
              "         [-2.48405820e-05],\n",
              "         [-2.90643791e-01],\n",
              "         [-2.13162996e-04],\n",
              "         [-2.85502143e-02],\n",
              "         [-1.37017781e-01],\n",
              "         [-2.05028605e-01],\n",
              "         [-1.97481348e-03],\n",
              "         [-8.58343104e-04],\n",
              "         [-1.24233126e-06],\n",
              "         [-5.91663827e-06],\n",
              "         [-7.26675339e-02],\n",
              "         [-3.98394628e-04],\n",
              "         [-5.58071176e-02],\n",
              "         [-6.64634777e-02],\n",
              "         [-2.01440301e-03],\n",
              "         [-1.91291617e-06],\n",
              "         [-4.16343289e-03],\n",
              "         [-5.30315950e-07],\n",
              "         [-7.50372705e-04],\n",
              "         [-4.04391094e-01],\n",
              "         [-1.02839863e+00],\n",
              "         [-4.73369451e-04],\n",
              "         [-9.51971722e-01],\n",
              "         [-3.82063566e-01],\n",
              "         [-6.70416959e-01],\n",
              "         [-6.28921822e-09],\n",
              "         [-5.64850721e-06],\n",
              "         [-2.47554135e-03],\n",
              "         [-1.99049798e-01],\n",
              "         [-3.09858245e-06],\n",
              "         [-7.40286794e-01],\n",
              "         [-9.41097315e-02],\n",
              "         [-2.60010957e-02],\n",
              "         [-5.76042810e-04]]),\n",
              "  array([[-1.05052866e+00],\n",
              "         [-7.57190809e-03],\n",
              "         [-1.07779105e-05],\n",
              "         [-7.58322935e-04],\n",
              "         [-7.00852448e-02],\n",
              "         [-8.91791557e-01],\n",
              "         [-2.39990195e-01],\n",
              "         [-3.30843577e-02],\n",
              "         [-4.27051753e-01],\n",
              "         [-1.39349738e-01],\n",
              "         [-2.30325596e-02],\n",
              "         [-8.09578614e-02],\n",
              "         [-1.37700712e-04],\n",
              "         [-5.64478233e-03],\n",
              "         [-3.44867552e-01],\n",
              "         [-3.13372675e-03],\n",
              "         [-3.05478322e-01],\n",
              "         [-3.14099021e-02],\n",
              "         [-9.33390401e-04],\n",
              "         [-5.97802418e-01],\n",
              "         [-9.09992252e-01],\n",
              "         [-9.01377136e-01],\n",
              "         [-1.32159914e-02],\n",
              "         [-7.90870705e-01],\n",
              "         [-4.37449613e-06],\n",
              "         [-3.73450106e-01],\n",
              "         [-5.66620410e-01],\n",
              "         [-2.03177560e-06],\n",
              "         [-1.29160583e-03],\n",
              "         [-2.10245006e-03],\n",
              "         [-1.76400068e-06],\n",
              "         [-9.85027170e-07],\n",
              "         [-1.18711512e-01],\n",
              "         [-5.89698096e-01],\n",
              "         [-2.81829694e-05],\n",
              "         [-2.32369369e-07],\n",
              "         [-3.41149363e-03],\n",
              "         [-8.15678378e-02],\n",
              "         [-5.23364995e-01],\n",
              "         [-1.56426512e-01],\n",
              "         [-4.54691906e-02],\n",
              "         [-1.15249700e-04],\n",
              "         [-5.94462719e-04],\n",
              "         [-4.13900127e-05],\n",
              "         [-2.37849508e-01],\n",
              "         [-9.68344308e-01],\n",
              "         [-2.24045375e-07],\n",
              "         [-7.17024488e-01],\n",
              "         [-9.04229745e-02],\n",
              "         [-3.00646073e-04],\n",
              "         [-1.23232949e-04],\n",
              "         [-1.56060005e-04],\n",
              "         [-6.47209671e-02],\n",
              "         [-4.86289226e-03],\n",
              "         [-6.26259664e-01],\n",
              "         [-5.63405715e-01],\n",
              "         [-1.41239615e-08],\n",
              "         [-5.40513941e-04],\n",
              "         [-2.49168564e-02],\n",
              "         [-1.11916750e+00],\n",
              "         [-9.84426730e-01],\n",
              "         [-4.86555743e-04],\n",
              "         [-5.50317728e-01],\n",
              "         [-8.46157729e-05]]),\n",
              "  array([[-6.26432505e-07],\n",
              "         [-3.01280177e-03],\n",
              "         [-1.95533583e-03],\n",
              "         [-1.11510761e+00],\n",
              "         [-4.99627630e-01],\n",
              "         [-4.68446247e-03],\n",
              "         [-7.91220249e-01],\n",
              "         [-9.59716827e-01],\n",
              "         [-4.61233637e-03],\n",
              "         [-1.08010070e+00]])],\n",
              " [array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
              "  array([[-1.05052214e+00, -1.39109780e-05, -6.15295912e-03, ...,\n",
              "          -2.02394088e-02, -1.04366625e+00, -1.21046633e-04],\n",
              "         [-7.57186107e-03, -1.00266323e-07, -4.43487575e-05, ...,\n",
              "          -1.45879830e-04, -7.52244576e-03, -8.72469277e-07],\n",
              "         [-1.07778436e-05, -1.42719834e-10, -6.31263527e-08, ...,\n",
              "          -2.07646440e-07, -1.07075055e-05, -1.24187929e-09],\n",
              "         ...,\n",
              "         [-4.86552722e-04, -6.44291437e-09, -2.84976288e-06, ...,\n",
              "          -9.37394755e-06, -4.83377392e-04, -5.60631392e-08],\n",
              "         [-5.50314311e-01, -7.28724313e-06, -3.22321760e-03, ...,\n",
              "          -1.06023813e-02, -5.46722862e-01, -6.34100816e-05],\n",
              "         [-8.46152474e-05, -1.12047219e-09, -4.95595607e-07, ...,\n",
              "          -1.63020132e-06, -8.40630332e-05, -9.74980959e-09]]),\n",
              "  array([[-3.78865665e-07, -9.50387682e-10, -1.35033019e-12,\n",
              "          -6.26313728e-07, -6.15307530e-07, -1.56942621e-07,\n",
              "          -5.86941706e-07, -6.21218588e-07, -5.52808830e-07,\n",
              "          -6.03999505e-07, -6.22809675e-07, -1.03474670e-08,\n",
              "          -6.26410939e-07, -6.25547548e-07, -5.68244159e-07,\n",
              "          -6.25941449e-07, -4.15415396e-08, -3.96532563e-09,\n",
              "          -1.16967425e-10, -9.00621254e-08, -1.62277228e-07,\n",
              "          -1.59724376e-07, -6.24357613e-07, -4.71444094e-07,\n",
              "          -5.48065888e-13, -5.62960973e-07, -5.24609539e-07,\n",
              "          -2.54554180e-13, -6.26230180e-07, -2.63541649e-10,\n",
              "          -6.26432228e-07, -1.23410637e-13, -1.53207599e-08,\n",
              "          -5.19654955e-07, -3.53096950e-12, -2.91127468e-14,\n",
              "          -4.27764583e-10, -1.04270424e-08, -7.65740790e-08,\n",
              "          -2.03902477e-08, -5.76013673e-09, -1.44396311e-11,\n",
              "          -7.44887827e-11, -5.18566138e-12, -5.87312996e-07,\n",
              "          -1.81155989e-07, -6.26432470e-07, -1.13954841e-07,\n",
              "          -1.15850877e-08, -3.76696128e-11, -1.54398817e-11,\n",
              "          -6.26408064e-07, -6.16169890e-07, -6.09967362e-10,\n",
              "          -5.11604068e-07, -5.25292348e-07, -6.26432503e-07,\n",
              "          -6.77278873e-11, -6.22511881e-07, -2.67915016e-07,\n",
              "          -4.09287301e-07, -6.09659865e-11, -8.13502357e-08,\n",
              "          -1.06014294e-11],\n",
              "         [-1.82213908e-03, -4.57085109e-06, -6.49435840e-09,\n",
              "          -3.01223052e-03, -2.95929666e-03, -7.54809181e-04,\n",
              "          -2.82287238e-03, -2.98772565e-03, -2.65871169e-03,\n",
              "          -2.90491117e-03, -2.99537792e-03, -4.97657235e-05,\n",
              "          -3.01269806e-03, -3.00854561e-03, -2.73294728e-03,\n",
              "          -3.01044006e-03, -1.99792353e-04, -1.90710731e-05,\n",
              "          -5.62550095e-07, -4.33150146e-04, -7.80465758e-04,\n",
              "          -7.68187920e-04, -3.00282267e-03, -2.26739129e-03,\n",
              "          -2.63590071e-09, -2.70753801e-03, -2.52308834e-03,\n",
              "          -1.22426802e-09, -3.01182870e-03, -1.26749289e-06,\n",
              "          -3.01280045e-03, -5.93538461e-10, -7.36845744e-05,\n",
              "          -2.49925947e-03, -1.69820549e-08, -1.40016577e-10,\n",
              "          -2.05731645e-06, -5.01484384e-05, -3.68279933e-04,\n",
              "          -9.80660709e-05, -2.77031444e-05, -6.94468212e-08,\n",
              "          -3.58250785e-07, -2.49402285e-08, -2.82465808e-03,\n",
              "          -8.71262395e-04, -3.01280161e-03, -5.48061196e-04,\n",
              "          -5.57180104e-05, -1.81170478e-07, -7.42574859e-08,\n",
              "          -3.01268423e-03, -2.96344415e-03, -2.93361334e-06,\n",
              "          -2.46053905e-03, -2.52637228e-03, -3.01280176e-03,\n",
              "          -3.25734532e-07, -2.99394569e-03, -1.28852642e-03,\n",
              "          -1.96845071e-03, -2.93213444e-07, -3.91250665e-04,\n",
              "          -5.09871456e-08],\n",
              "         [-1.18258488e-03, -2.96652405e-06, -4.21489784e-09,\n",
              "          -1.95496509e-03, -1.92061053e-03, -4.89878044e-04,\n",
              "          -1.83206992e-03, -1.93906120e-03, -1.72552814e-03,\n",
              "          -1.88531385e-03, -1.94402759e-03, -3.22984085e-05,\n",
              "          -1.95526852e-03, -1.95257354e-03, -1.77370771e-03,\n",
              "          -1.95380306e-03, -1.29667060e-04, -1.23773004e-05,\n",
              "          -3.65100143e-07, -2.81118396e-04, -5.06529396e-04,\n",
              "          -4.98560967e-04, -1.94885930e-03, -1.47155763e-03,\n",
              "          -1.71072360e-09, -1.75721687e-03, -1.63750735e-03,\n",
              "          -7.94561115e-10, -1.95470430e-03, -8.22614450e-07,\n",
              "          -1.95533497e-03, -3.85211875e-10, -4.78219609e-05,\n",
              "          -1.62204220e-03, -1.10215085e-08, -9.08720360e-11,\n",
              "          -1.33521714e-06, -3.25467940e-05, -2.39017036e-04,\n",
              "          -6.36457745e-05, -1.79795934e-05, -4.50716204e-08,\n",
              "          -2.32508027e-07, -1.61864358e-08, -1.83322886e-03,\n",
              "          -5.65457242e-04, -1.95533572e-03, -3.55696716e-04,\n",
              "          -3.61614970e-05, -1.17581293e-07, -4.81937857e-08,\n",
              "          -1.95525954e-03, -1.92330228e-03, -1.90394181e-06,\n",
              "          -1.59691229e-03, -1.63963866e-03, -1.95533583e-03,\n",
              "          -2.11404683e-07, -1.94309806e-03, -8.36265402e-04,\n",
              "          -1.27754246e-03, -1.90298200e-07, -2.53925251e-04,\n",
              "          -3.30911226e-08],\n",
              "         [-6.74415812e-01, -1.69177769e-03, -2.40371223e-06,\n",
              "          -1.11489618e+00, -1.09530413e+00, -2.79372334e-01,\n",
              "          -1.04481035e+00, -1.10582636e+00, -9.84050681e-01,\n",
              "          -1.07517480e+00, -1.10865864e+00, -1.84194451e-02,\n",
              "          -1.11506922e+00, -1.11353231e+00, -1.01152699e+00,\n",
              "          -1.11423349e+00, -7.39477703e-02, -7.05864518e-03,\n",
              "          -2.08212799e-04, -1.60318886e-01, -2.88868426e-01,\n",
              "          -2.84324114e-01, -1.11141411e+00, -8.39213950e-01,\n",
              "          -9.75607808e-07, -1.00212243e+00, -9.33853344e-01,\n",
              "          -4.53129908e-07, -1.11474745e+00, -4.69128432e-04,\n",
              "          -1.11510712e+00, -2.19682311e-07, -2.72723650e-02,\n",
              "          -9.25033728e-01, -6.28545124e-06, -5.18233733e-08,\n",
              "          -7.61460394e-04, -1.85610968e-02, -1.36308920e-01,\n",
              "          -3.62965207e-02, -1.02535744e-02, -2.57038745e-05,\n",
              "          -1.32596900e-04, -9.23095533e-06, -1.04547128e+00,\n",
              "          -3.22474361e-01, -1.11510755e+00, -2.02850123e-01,\n",
              "          -2.06225242e-02, -6.70553835e-05, -2.74844128e-05,\n",
              "          -1.11506410e+00, -1.09683921e+00, -1.08579814e-03,\n",
              "          -9.10702406e-01, -9.35068806e-01, -1.11510761e+00,\n",
              "          -1.20561883e-04, -1.10812854e+00, -4.76913427e-01,\n",
              "          -7.28569128e-01, -1.08525077e-04, -1.44810919e-01,\n",
              "          -1.88715217e-05],\n",
              "         [-3.02174222e-01, -7.58006556e-04, -1.07699117e-06,\n",
              "          -4.99532897e-01, -4.90754616e-01, -1.25173692e-01,\n",
              "          -4.68130711e-01, -4.95469135e-01, -4.40907142e-01,\n",
              "          -4.81735604e-01, -4.96738147e-01, -8.25289295e-03,\n",
              "          -4.99610430e-01, -4.98921810e-01, -4.53217993e-01,\n",
              "          -4.99235976e-01, -3.31325416e-02, -3.16264918e-03,\n",
              "          -9.32904292e-05, -7.18314039e-02, -1.29428448e-01,\n",
              "          -1.27392354e-01, -4.97972746e-01, -3.76012569e-01,\n",
              "          -4.37124286e-07, -4.49004250e-01, -4.18416060e-01,\n",
              "          -2.03026345e-07, -4.99466261e-01, -2.10194536e-04,\n",
              "          -4.99627410e-01, -9.84293814e-08, -1.22194728e-02,\n",
              "          -4.14464403e-01, -2.81621709e-06, -2.32196328e-08,\n",
              "          -3.41174833e-04, -8.31636043e-03, -6.10736597e-02,\n",
              "          -1.62627754e-02, -4.59414772e-03, -1.15167055e-05,\n",
              "          -5.94104771e-05, -4.13595988e-06, -4.68426843e-01,\n",
              "          -1.44485697e-01, -4.99627602e-01, -9.08876645e-02,\n",
              "          -9.23998974e-03, -3.00443850e-05, -1.23144815e-05,\n",
              "          -4.99608137e-01, -4.91442414e-01, -4.86495425e-04,\n",
              "          -4.08043207e-01, -4.18960652e-01, -4.99627629e-01,\n",
              "          -5.40181481e-05, -4.96500634e-01, -2.13682629e-01,\n",
              "          -3.26437793e-01, -4.86250173e-05, -6.48830084e-02,\n",
              "          -8.45544733e-06],\n",
              "         [-2.83315756e-03, -7.10699938e-06, -1.00977696e-08,\n",
              "          -4.68357426e-03, -4.60126991e-03, -1.17361697e-03,\n",
              "          -4.38915026e-03, -4.64547280e-03, -4.13390460e-03,\n",
              "          -4.51670849e-03, -4.65737094e-03, -7.73783612e-05,\n",
              "          -4.68430120e-03, -4.67784476e-03, -4.24933000e-03,\n",
              "          -4.68079035e-03, -3.10647646e-04, -2.96527063e-05,\n",
              "          -8.74682439e-07, -6.73484602e-04, -1.21350916e-03,\n",
              "          -1.19441893e-03, -4.66894643e-03, -3.52545908e-03,\n",
              "          -4.09843689e-09, -4.20982234e-03, -3.92303030e-03,\n",
              "          -1.90355624e-09, -4.68294948e-03, -1.97076454e-06,\n",
              "          -4.68446040e-03, -9.22864779e-10, -1.14568647e-04,\n",
              "          -3.88597992e-03, -2.64045910e-08, -2.17705130e-10,\n",
              "          -3.19882369e-06, -7.79734265e-05, -5.72620987e-04,\n",
              "          -1.52478279e-04, -4.30743043e-05, -1.07979566e-07,\n",
              "          -5.57027140e-07, -3.87783774e-08, -4.39192677e-03,\n",
              "          -1.35468454e-03, -4.68446221e-03, -8.52154339e-04,\n",
              "          -8.66332895e-05, -2.81693376e-07, -1.15459440e-07,\n",
              "          -4.68427970e-03, -4.60771863e-03, -4.56133612e-06,\n",
              "          -3.82577538e-03, -3.92813634e-03, -4.68446245e-03,\n",
              "          -5.06469163e-07, -4.65514404e-03, -2.00346857e-03,\n",
              "          -3.06065057e-03, -4.55903666e-07, -6.08337088e-04,\n",
              "          -7.92774924e-08],\n",
              "         [-4.78529106e-01, -1.20039425e-03, -1.70554463e-06,\n",
              "          -7.91070228e-01, -7.77168767e-01, -1.98227548e-01,\n",
              "          -7.41341102e-01, -7.84634773e-01, -6.98229317e-01,\n",
              "          -7.62886082e-01, -7.86644407e-01, -1.30694454e-02,\n",
              "          -7.91193011e-01, -7.90102498e-01, -7.17725024e-01,\n",
              "          -7.90600018e-01, -5.24693516e-02, -5.00843412e-03,\n",
              "          -1.47736579e-04, -1.13753640e-01, -2.04965463e-01,\n",
              "          -2.01741065e-01, -7.88599542e-01, -5.95460981e-01,\n",
              "          -6.92238710e-07, -7.11052058e-01, -6.62611993e-01,\n",
              "          -3.21516556e-07, -7.90964701e-01, -3.32868246e-04,\n",
              "          -7.91219900e-01, -1.55874725e-07, -1.93510001e-02,\n",
              "          -6.56354069e-01, -4.45981738e-06, -3.67710721e-08,\n",
              "          -5.40291249e-04, -1.31699537e-02, -9.67174618e-02,\n",
              "          -2.57540545e-02, -7.27538368e-03, -1.82380838e-05,\n",
              "          -9.40836128e-05, -6.54978830e-06, -7.41810062e-01,\n",
              "          -2.28810423e-01, -7.91220205e-01, -1.43931513e-01,\n",
              "          -1.46326315e-02, -4.75788855e-05, -1.95014577e-05,\n",
              "          -7.91189379e-01, -7.78257978e-01, -7.70423828e-04,\n",
              "          -6.46185335e-01, -6.63474419e-01, -7.91220247e-01,\n",
              "          -8.55442134e-05, -7.86268276e-01, -3.38392060e-01,\n",
              "          -5.16953380e-01, -7.70035442e-05, -1.02750022e-01,\n",
              "          -1.33902145e-05],\n",
              "         [-5.80435644e-01, -1.45602765e-03, -2.06875377e-06,\n",
              "          -9.59534857e-01, -9.42672971e-01, -2.40441664e-01,\n",
              "          -8.99215522e-01, -9.51728921e-01, -8.46922744e-01,\n",
              "          -9.25348675e-01, -9.54166522e-01, -1.58526866e-02,\n",
              "          -9.59683787e-01, -9.58361041e-01, -8.70570215e-01,\n",
              "          -9.58964512e-01, -6.36431128e-02, -6.07501957e-03,\n",
              "          -1.79198245e-04, -1.37978372e-01, -2.48614471e-01,\n",
              "          -2.44703412e-01, -9.56538019e-01, -7.22269081e-01,\n",
              "          -8.39656390e-07, -8.62476188e-01, -8.03720430e-01,\n",
              "          -3.89986037e-07, -9.59406858e-01, -4.03755158e-04,\n",
              "          -9.59716403e-01, -1.89069475e-07, -2.34719478e-02,\n",
              "          -7.96129832e-01, -5.40957058e-06, -4.46017612e-08,\n",
              "          -6.55350521e-04, -1.59745990e-02, -1.17314206e-01,\n",
              "          -3.12385830e-02, -8.82473387e-03, -2.21220272e-05,\n",
              "          -1.14119458e-04, -7.94461725e-06, -8.99784351e-01,\n",
              "          -2.77537403e-01, -9.59716773e-01, -1.74582861e-01,\n",
              "          -1.77487655e-02, -5.77111835e-05, -2.36544466e-05,\n",
              "          -9.59679382e-01, -9.43994137e-01, -9.34491644e-04,\n",
              "          -7.83795586e-01, -8.04766517e-01, -9.59716823e-01,\n",
              "          -1.03761527e-04, -9.53710292e-01, -4.10455311e-01,\n",
              "          -6.27042669e-01, -9.34020547e-05, -1.24631448e-01,\n",
              "          -1.62417660e-05],\n",
              "         [-2.78953578e-03, -6.99757378e-06, -9.94229547e-09,\n",
              "          -4.61146184e-03, -4.53042471e-03, -1.15554693e-03,\n",
              "          -4.32157105e-03, -4.57394702e-03, -4.07025538e-03,\n",
              "          -4.44716528e-03, -4.58566197e-03, -7.61869760e-05,\n",
              "          -4.61217759e-03, -4.60582055e-03, -4.18390358e-03,\n",
              "          -4.60872079e-03, -3.05864642e-04, -2.91961472e-05,\n",
              "          -8.61215060e-07, -6.63115042e-04, -1.19482491e-03,\n",
              "          -1.17602861e-03, -4.59705923e-03, -3.47117802e-03,\n",
              "          -4.03533375e-09, -4.14500422e-03, -3.86262788e-03,\n",
              "          -1.87424741e-09, -4.61084668e-03, -1.94042091e-06,\n",
              "          -4.61233434e-03, -9.08655543e-10, -1.12804648e-04,\n",
              "          -3.82614796e-03, -2.59980428e-08, -2.14353151e-10,\n",
              "          -3.14957179e-06, -7.67728791e-05, -5.63804411e-04,\n",
              "          -1.50130589e-04, -4.24110945e-05, -1.06317018e-07,\n",
              "          -5.48450661e-07, -3.81813115e-08, -4.32430481e-03,\n",
              "          -1.33382663e-03, -4.61233611e-03, -8.39033823e-04,\n",
              "          -8.52994073e-05, -2.77356177e-07, -1.13681725e-07,\n",
              "          -4.61215641e-03, -4.53677415e-03, -4.49110579e-06,\n",
              "          -3.76687038e-03, -3.86765530e-03, -4.61233635e-03,\n",
              "          -4.98671119e-07, -4.58346936e-03, -1.97262141e-03,\n",
              "          -3.01352610e-03, -4.48884173e-07, -5.98970596e-04,\n",
              "          -7.80568665e-08],\n",
              "         [-6.53243676e-01, -1.63866721e-03, -2.32825178e-06,\n",
              "          -1.07989591e+00, -1.06091892e+00, -2.70601915e-01,\n",
              "          -1.01201031e+00, -1.07111082e+00, -9.53158085e-01,\n",
              "          -1.04142152e+00, -1.07385419e+00, -1.78411980e-02,\n",
              "          -1.08006352e+00, -1.07857485e+00, -9.79771821e-01,\n",
              "          -1.07925402e+00, -7.16263059e-02, -6.83705103e-03,\n",
              "          -2.01676313e-04, -1.55285948e-01, -2.79799893e-01,\n",
              "          -2.75398243e-01, -1.07652316e+00, -8.12868257e-01,\n",
              "          -9.44980262e-07, -9.70662505e-01, -9.04536608e-01,\n",
              "          -4.38904666e-07, -1.07975185e+00, -4.54400943e-04,\n",
              "          -1.08010023e+00, -2.12785758e-07, -2.64161955e-02,\n",
              "          -8.95993869e-01, -6.08813020e-06, -5.01964667e-08,\n",
              "          -7.37555641e-04, -1.79784027e-02, -1.32029734e-01,\n",
              "          -3.51570532e-02, -9.93168090e-03, -2.48969451e-05,\n",
              "          -1.28434246e-04, -8.94116520e-06, -1.01265049e+00,\n",
              "          -3.12350827e-01, -1.08010064e+00, -1.96481989e-01,\n",
              "          -1.99751151e-02, -6.49502939e-05, -2.66215864e-05,\n",
              "          -1.08005856e+00, -1.06240581e+00, -1.05171135e-03,\n",
              "          -8.82112454e-01, -9.05713913e-01, -1.08010070e+00,\n",
              "          -1.16777048e-04, -1.07334073e+00, -4.61941542e-01,\n",
              "          -7.05696941e-01, -1.05118116e-04, -1.40264827e-01,\n",
              "          -1.82790824e-05]])])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net=Network([784,128,64,10])\n",
        "nabla_b,nabla_w=net.backpropagation(train_X[0],train_y[0])\n",
        "for nb in nabla_b:\n",
        "  print(nb.shape)\n",
        "for nw in nabla_w:\n",
        "  print(nw.shape)\n",
        "\n",
        "# Desired output:\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pq4E3rHik-f",
        "outputId": "bbad2931-7315-4de4-ff48-8e2c5291db36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXljiAYRlvdq",
        "outputId": "f0763152-9b7e-4544-ef20-4e4820f5cf54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1032/10000 classified correctly.\n",
            "Epoch 1 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 2 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 3 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 4 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 5 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 6 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 7 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 8 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 9 completed.\n",
            "1032/10000 classified correctly.\n",
            "Epoch 10 completed.\n",
            "107/1000 classified correctly.\n"
          ]
        }
      ],
      "source": [
        "net=Network([784,128,64,10])\n",
        "net.SGD(train_data=train_data,epochs=10,mini_batch_size=20,lr=0.01)\n",
        "#print(\"Test data:\")\n",
        "net.predict(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of question 1."
      ],
      "metadata": {
        "id": "mhMIoFT9m7OU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 2 :\n",
        "## Stochastic Gradient Descent\n",
        "Implement logistic regression using \"Stochastic gradient descent\" and use iris-dataset as training data.\n",
        "\n",
        "\n",
        "The word 'stochastic' means a system or process linked with a random probability. Hence, in Stochastic Gradient Descent, a few samples are selected randomly instead of the whole data set for each iteration. In Gradient Descent, there is a term called “batch” which denotes the total number of samples from a dataset that is used for calculating the gradient for each iteration. In typical Gradient Descent optimization, like Batch Gradient Descent, the batch is taken to be the whole dataset. Although using the whole dataset is really useful for getting to the minima in a less noisy and less random manner, the problem arises when our dataset gets big.\n",
        "Suppose, you have a million samples in your dataset, so if you use a typical Gradient Descent optimization technique, you will have to use all of the one million samples for completing one iteration while performing the Gradient Descent, and it has to be done for every iteration until the minima are reached. Hence, it becomes computationally very expensive to perform.\n",
        "This problem is solved by Stochastic Gradient Descent. In SGD, it uses only a single sample, i.e., a batch size of one, to perform each iteration. The sample is randomly shuffled and selected for performing the iteration.\n",
        "\n",
        "    Stochastic Gradient Descent (SGD) is a variant of the Gradient Descent algorithm used for optimizing machine learning models. In this variant, only one random training example is used to calculate the gradient and update the parameters at each iteration. Here are some of the advantages and disadvantages of using SGD:\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Speed: SGD is faster than other variants of Gradient Descent such as Batch Gradient Descent and Mini-Batch Gradient Descent since it uses only one example to update the parameters.\n",
        "\n",
        "Memory Efficiency: Since SGD updates the parameters for each training example one at a time, it is memory-efficient and can handle large datasets that cannot fit into memory.\n",
        "\n",
        "Avoidance of Local Minima: Due to the noisy updates in SGD, it has the ability to escape from local minima and converge to a global minimum.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Noisy updates: The updates in SGD are noisy and have a high variance, which can make the optimization process less stable and lead to oscillations around the minimum.\n",
        "\n",
        "Slow Convergence: SGD may require more iterations to converge to the minimum since it updates the parameters for each training example one at a time.\n",
        "\n",
        "Sensitivity to Learning Rate: The choice of learning rate can be critical in SGD since using a high learning rate can cause the algorithm to overshoot the minimum, while a low learning rate can make the algorithm converge slowly.\n",
        "\n",
        "Less Accurate: Due to the noisy updates, SGD may not converge to the exact global minimum and can result in a suboptimal solution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "So, in SGD, we find out the gradient of the cost function of a single example at each iteration instead of the sum of the gradient of the cost function of all the examples.\n",
        "\n",
        "In SGD, since only one sample from the dataset is chosen at random for each iteration, the path taken by the algorithm to reach the minima is usually noisier than your typical Gradient Descent algorithm. But that doesn’t matter all that much because the path taken by the algorithm does not matter, as long as we reach the minima and with a significantly shorter training time."
      ],
      "metadata": {
        "id": "Aa_iPRK6nEay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "# pre load sklearn iris datasets\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "Y = iris.target\n",
        "\n",
        "dataset = []\n",
        "\n",
        "target_label = 0 # choose the target label of flower type\n",
        "for index, x in enumerate(X):\n",
        "    transform_label = None\n",
        "    if Y[target_label]==target_label:\n",
        "      transform_label=1\n",
        "\n",
        "    else:\n",
        "      transform_label=0\n",
        "    x = [x[0], x[2]]\n",
        "    dataset.append((x,transform_label))\n",
        "print(x)\n",
        "dataset = np.array(dataset)\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sgd(dataset, w):\n",
        "    #run sgd randomly\n",
        "    grad=np.zeros(2)\n",
        "    index = random.randint(0, len(dataset) - 1)\n",
        "    x,y=dataset[index]\n",
        "    for x ,y in dataset:\n",
        "      y_pred=sigmoid (np.dot(x,w))\n",
        "      grad += (y_pred - y) **2\n",
        "      return grad/len(dataset)\n",
        "\n",
        "def cost(dataset, w):\n",
        "    total_cost = 0\n",
        "    for x,y in dataset:\n",
        "       y_pred = sigmoid(np.dot(x,w))\n",
        "       total_cost += -y * np.log(y_pred) - (1 - y) * np.log(1 - y_pred)\n",
        "    return total_cost/(2*len(dataset))\n",
        "\n",
        "def logistic_regression(dataset):\n",
        "    w = np.zeros(2)\n",
        "    limit = 1500 #update times\n",
        "    eta = 0.1 #update rate\n",
        "    costs = []\n",
        "    for i in range(limit):\n",
        "       dw=sgd(dataset,w)\n",
        "       w-= eta * dw\n",
        "       new_cost=cost(dataset,w)\n",
        "       costs.append(new_cost)\n",
        "       eta = eta * 0.98 #decrease update rate\n",
        "    plt.plot(range(limit), costs)\n",
        "    plt.show()\n",
        "    return w,(limit, costs)\n",
        "\n",
        "def main():\n",
        "    #execute\n",
        "    w = logistic_regression(dataset)\n",
        "    #draw\n",
        "    ps = [v[0] for v in dataset]\n",
        "    label = [v[1] for v in dataset]\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    #plot via label\n",
        "    tpx=[]\n",
        "    for index, label_value in enumerate(label):\n",
        "        px=ps[index][0]\n",
        "        py=ps[index][1]\n",
        "        tpx.append(px)\n",
        "        if label_value == 1:\n",
        "            ax1.scatter(px, py, c='b', marker=\"o\", label='O')\n",
        "        else:\n",
        "            ax1.scatter(px, py, c='r', marker=\"x\", label='X')\n",
        "\n",
        "    l = np.linspace(min(tpx),max(tpx))\n",
        "    a,b = (-w[0][0]/w[0][1], w[0][0])\n",
        "    ax1.plot(l, a*l + b, 'g-')\n",
        "    #plt.legend(loc='upper left');\n",
        "    plt.show()\n",
        "\n",
        "    limit = w[1][0]\n",
        "    costs = w[1][1]\n",
        "    w = w[0]\n",
        "\n",
        "    # calculate score\n",
        "    predicted_Y=[]\n",
        "    answer_Y=[]\n",
        "    for X,Y in dataset:\n",
        "        '...'\n",
        "    predicted_Y = np.asarray(predicted_Y)\n",
        "    predicted_Y = predicted_Y > 0.5\n",
        "    print(answer_Y)\n",
        "    print(predicted_Y)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "RMgp1wALns9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "d062d79b-ccac-4141-d29e-a59c6711f15c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.9, 5.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-3ad515ad87e7>:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  dataset = np.array(dataset)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3 :\n",
        "## Implement linear regression using \"mini-batch\" gradient descent\n",
        "\n",
        "\n",
        "Mini-Batch Gradient Descent: Parameters are updated after computing the gradient of  the error with respect to a subset of the training set.\n",
        "Thus, mini-batch gradient descent makes a compromise between the speedy convergence and the noise associated with gradient update which makes it a more flexible and robust algorithm.\n",
        "\n",
        "\n",
        " Mini-Batch Gradient Descent: Algorithm-\n",
        "\n",
        "    Let theta = model parameters and max_iters = number of epochs. for itr = 1, 2, 3, …, max_iters:       for mini_batch (X_mini, y_mini):\n",
        "\n",
        "        Forward Pass on the batch X_mini:\n",
        "            Make predictions on the mini-batch\n",
        "            Compute error in predictions (J(theta)) with the current values of the parameters\n",
        "        Backward Pass:\n",
        "            Compute gradient(theta) = partial derivative of J(theta) w.r.t. theta\n",
        "        Update parameters:\n",
        "            theta = theta – learning_rate*gradient(theta)"
      ],
      "metadata": {
        "id": "I1CbSYwCn0BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# creating data\n",
        "mean = np.array([5.0, 6.0])\n",
        "cov = np.array([[1.0, 0.95], [0.95, 1.2]])\n",
        "data = np.random.multivariate_normal(mean, cov, 8000)\n",
        "\n",
        "# visualising data\n",
        "plt.scatter(data[:500, 0], data[:500, 1], marker='.')\n",
        "plt.show()\n",
        "\n",
        "# train-test-split\n",
        "data = np.hstack((np.ones((data.shape[0], 1)), data))\n",
        "\n",
        "split_factor = 0.90\n",
        "split = int(split_factor * data.shape[0])\n",
        "\n",
        "X_train = data[:split, :-1]\n",
        "y_train = data[:split, -1].reshape((-1, 1))\n",
        "X_test = data[split:, :-1]\n",
        "y_test = data[split:, -1].reshape((-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "# linear regression using \"mini-batch\" gradient descent\n",
        "# function to compute hypothesis / predictions\n",
        "\n",
        "\n",
        "def hypothesis(X, theta):\n",
        "\treturn '...'\n",
        "\n",
        "# function to compute gradient of error function w.r.t. theta\n",
        "\n",
        "\n",
        "def gradient(X, y, theta):\n",
        "\t'...'\n",
        "\n",
        "# function to compute the error for current values of theta\n",
        "\n",
        "\n",
        "def cost(X, y, theta):\n",
        "\t'...'\n",
        "\n",
        "# function to create a list containing mini-batches\n",
        "\n",
        "\n",
        "def create_mini_batches(X, y, batch_size):\n",
        "\tmini_batches = []\n",
        "\tdata = np.hstack((X, y))\n",
        "\tnp.random.shuffle(data)\n",
        "\tn_minibatches = data.shape[0] // batch_size\n",
        "\ti = 0\n",
        "\n",
        "\tfor i in range(n_minibatches + 1):\n",
        "\t\t'...'\n",
        "\tif data.shape[0] % batch_size != 0:\n",
        "\t\t'...'\n",
        "\treturn '...'\n",
        "\n",
        "# function to perform mini-batch gradient descent\n",
        "\n",
        "\n",
        "def gradientDescent(X, y, learning_rate=0.001, batch_size=32):\n",
        "\t'...'\n",
        "\n",
        "\n",
        "theta, error_list = gradientDescent(X_train, y_train)\n",
        "print(\"Bias = \", theta[0])\n",
        "print(\"Coefficients = \", theta[1:])\n",
        "\n",
        "# visualising gradient descent\n",
        "plt.plot(error_list)\n",
        "plt.xlabel(\"Number of iterations\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# predicting output for X_test\n",
        "y_pred = hypothesis(X_test, theta)\n",
        "plt.scatter(X_test[:, 1], y_test[:, ], marker='.')\n",
        "plt.plot(X_test[:, 1], y_pred, color='orange')\n",
        "plt.show()\n",
        "\n",
        "# calculating error in predictions\n",
        "error = '...'\n",
        "\n"
      ],
      "metadata": {
        "id": "Oz46YIVYseN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}